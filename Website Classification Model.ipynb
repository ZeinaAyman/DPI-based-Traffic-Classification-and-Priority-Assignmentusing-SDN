{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "READING AND VIEWING THE DATASET.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>website_url</th>\n",
       "      <th>cleaned_website_text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.booking.com/index.html?aid=1743217</td>\n",
       "      <td>official site good hotel accommodation big sav...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://travelsites.com/expedia/</td>\n",
       "      <td>expedia hotel book sites like use vacation wor...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://travelsites.com/tripadvisor/</td>\n",
       "      <td>tripadvisor hotel book sites like previously d...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.momondo.in/?ispredir=true</td>\n",
       "      <td>cheap flights search compare flights momondo f...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.ebookers.com/?AFFCID=EBOOKERS-UK.n...</td>\n",
       "      <td>bot create free account create free account si...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1387</td>\n",
       "      <td>http://www.electroshops.com/</td>\n",
       "      <td>electroshops home theater decor interiors seat...</td>\n",
       "      <td>Business/Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1388</td>\n",
       "      <td>http://www.cleanridge.com/</td>\n",
       "      <td>clean ridge soap company clean ridge soap comp...</td>\n",
       "      <td>Business/Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1389</td>\n",
       "      <td>http://www.creativepetgifts.com/</td>\n",
       "      <td>home page pet crafts exquisitely piece handcut...</td>\n",
       "      <td>Business/Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1390</td>\n",
       "      <td>http://www.htmarket.com/</td>\n",
       "      <td>home theater marketplace home theater seating ...</td>\n",
       "      <td>Business/Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1391</td>\n",
       "      <td>https://thrivemarket.com/web/membership/welcome</td>\n",
       "      <td>thrive market healthy living easy buy healthy ...</td>\n",
       "      <td>Business/Corporate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1409 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                        website_url  \\\n",
       "0             0     https://www.booking.com/index.html?aid=1743217   \n",
       "1             1                   https://travelsites.com/expedia/   \n",
       "2             2               https://travelsites.com/tripadvisor/   \n",
       "3             3              https://www.momondo.in/?ispredir=true   \n",
       "4             4  https://www.ebookers.com/?AFFCID=EBOOKERS-UK.n...   \n",
       "...         ...                                                ...   \n",
       "1404       1387                       http://www.electroshops.com/   \n",
       "1405       1388                         http://www.cleanridge.com/   \n",
       "1406       1389                   http://www.creativepetgifts.com/   \n",
       "1407       1390                           http://www.htmarket.com/   \n",
       "1408       1391    https://thrivemarket.com/web/membership/welcome   \n",
       "\n",
       "                                   cleaned_website_text            Category  \n",
       "0     official site good hotel accommodation big sav...              Travel  \n",
       "1     expedia hotel book sites like use vacation wor...              Travel  \n",
       "2     tripadvisor hotel book sites like previously d...              Travel  \n",
       "3     cheap flights search compare flights momondo f...              Travel  \n",
       "4     bot create free account create free account si...              Travel  \n",
       "...                                                 ...                 ...  \n",
       "1404  electroshops home theater decor interiors seat...  Business/Corporate  \n",
       "1405  clean ridge soap company clean ridge soap comp...  Business/Corporate  \n",
       "1406  home page pet crafts exquisitely piece handcut...  Business/Corporate  \n",
       "1407  home theater marketplace home theater seating ...  Business/Corporate  \n",
       "1408  thrive market healthy living easy buy healthy ...  Business/Corporate  \n",
       "\n",
       "[1409 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forums                              16\n",
      "Social Networking and Messaging     83\n",
      "Law and Government                  83\n",
      "Photography                         91\n",
      "Food                                91\n",
      "News                                92\n",
      "Computers and Technology            93\n",
      "Health and Fitness                  96\n",
      "Games                               98\n",
      "E-Commerce                         102\n",
      "Streaming Services                 103\n",
      "Sports                             103\n",
      "Travel                             106\n",
      "Business/Corporate                 109\n",
      "Education                          110\n",
      "Name: Category, dtype: int64\n",
      "Dataset size:  (1409, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"c:/website_classification.csv\" , low_memory=False) \n",
    "df = pd.DataFrame(dataset)\n",
    "display(df)\n",
    "print (df['Category'].value_counts(ascending=True))\n",
    "print(\"Dataset size: \" ,df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping duplicate coloumn and missing value rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forums                              16\n",
      "Social Networking and Messaging     83\n",
      "Law and Government                  83\n",
      "Photography                         91\n",
      "Food                                91\n",
      "News                                92\n",
      "Computers and Technology            93\n",
      "Health and Fitness                  96\n",
      "Games                               98\n",
      "E-Commerce                         102\n",
      "Streaming Services                 103\n",
      "Sports                             103\n",
      "Travel                             106\n",
      "Business/Corporate                 109\n",
      "Education                          110\n",
      "Name: Category, dtype: int64\n",
      "Dataset size after removal :  (1376, 3)\n"
     ]
    }
   ],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "print (df['Category'].value_counts(ascending=True))\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True) #replace infinity values with NaN\n",
    "df.dropna(inplace=True) #dropping rows with missing values  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['cleaned_website_text']      \n",
    "y=df['Category']  \n",
    "\n",
    "x=CountVectorizer().fit_transform(x.apply(lambda x: np.str_(x)))\n",
    "   \n",
    "x=TfidfTransformer().fit_transform(x) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing dataset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({963: 1})\n",
      "After Counter({'Law and Government': 77, 'Photography': 77, 'E-Commerce': 77, 'Travel': 77, 'Health and Fitness': 77, 'Forums': 77, 'Computers and Technology': 77, 'Streaming Services': 77, 'Food': 77, 'Games': 77, 'Social Networking and Messaging': 77, 'Sports': 77, 'News': 77, 'Education': 77, 'Business/Corporate': 77})\n",
      "Dataset size after balance :  (1155,)\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train.shape) \n",
    "print('Before', counter) \n",
    "smtom = SMOTE() \n",
    "X_train_smtom, y_train_smtom = smtom.fit_resample (X_train, y_train)\n",
    "counter = Counter(y_train_smtom) \n",
    "print('After', counter)\n",
    "print(\"Dataset size after balance : \" ,y_train_smtom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tunning of naive bayes and applying the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 28.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.001873817422860383}\n",
      "GaussianNB(var_smoothing=0.001873817422860383)\n"
     ]
    }
   ],
   "source": [
    "NB_classifier = GaussianNB()\n",
    "parameters={'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "grid=GridSearchCV(estimator = NB_classifier, param_grid =parameters, n_jobs=-1, verbose=-1)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train_smtom.todense(),y_train_smtom)\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "             Business/Corporate       0.76      0.63      0.69        41\n",
      "       Computers and Technology       0.76      0.66      0.70        29\n",
      "                     E-Commerce       0.79      0.81      0.80        32\n",
      "                      Education       0.91      0.64      0.75        33\n",
      "                           Food       0.82      0.86      0.84        21\n",
      "                         Forums       0.09      0.12      0.11         8\n",
      "                          Games       0.70      0.87      0.78        30\n",
      "             Health and Fitness       0.88      0.73      0.80        30\n",
      "             Law and Government       0.79      0.97      0.87        31\n",
      "                           News       0.68      0.65      0.67        26\n",
      "                    Photography       0.84      0.80      0.82        20\n",
      "Social Networking and Messaging       0.65      0.88      0.75        17\n",
      "                         Sports       0.83      0.91      0.87        32\n",
      "             Streaming Services       0.87      0.90      0.89        30\n",
      "                         Travel       0.81      0.79      0.80        33\n",
      "\n",
      "                       accuracy                           0.77       413\n",
      "                      macro avg       0.75      0.75      0.74       413\n",
      "                   weighted avg       0.78      0.77      0.77       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = GaussianNB(var_smoothing=0.001873817422860383)\n",
    "classifier.fit(X_train_smtom.todense(),y_train_smtom)\n",
    "y_pred=classifier.predict(X_test.todense())\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tunning of SVM and applying the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "SVC(C=10, gamma=0.001, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],'gamma':[0.001, 0.01, 0.1, 1, 3, 5, 10, 20],\n",
    "                'kernel': ['linear', 'rbf', 'poly']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train_smtom,y_train_smtom)\n",
    "\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "             Business/Corporate       0.75      0.88      0.81        41\n",
      "       Computers and Technology       0.69      0.93      0.79        29\n",
      "                     E-Commerce       0.93      0.88      0.90        32\n",
      "                      Education       0.89      1.00      0.94        33\n",
      "                           Food       0.91      0.95      0.93        21\n",
      "                         Forums       1.00      0.12      0.22         8\n",
      "                          Games       0.93      0.93      0.93        30\n",
      "             Health and Fitness       0.96      0.87      0.91        30\n",
      "             Law and Government       0.94      0.94      0.94        31\n",
      "                           News       0.92      0.88      0.90        26\n",
      "                    Photography       1.00      0.90      0.95        20\n",
      "Social Networking and Messaging       0.92      0.71      0.80        17\n",
      "                         Sports       0.97      0.94      0.95        32\n",
      "             Streaming Services       1.00      0.93      0.97        30\n",
      "                         Travel       0.94      0.94      0.94        33\n",
      "\n",
      "                       accuracy                           0.90       413\n",
      "                      macro avg       0.92      0.85      0.86       413\n",
      "                   weighted avg       0.91      0.90      0.89       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(C=10, gamma=0.001, kernel='linear')\n",
    "svc.fit(X_train_smtom,y_train_smtom)\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
